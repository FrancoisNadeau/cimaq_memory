{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# taskfilesdir = os.path.expanduser(\"~/../../data/cisl/DATA/cimaq_03-19/derivatives/CIMAQ_fmri_memory/data/task_files/processed\")\n",
    "# outTask_dir = os.path.expanduser(\"~/cimaq_memory/NEW_task_files\")\n",
    "\n",
    "import glob\n",
    "import nibabel\n",
    "import nilearn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sys\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from nilearn.plotting import plot_design_matrix\n",
    "from nilearn.glm.first_level import FirstLevelModel\n",
    "from nilearn.glm.first_level import make_first_level_design_matrix\n",
    "from nilearn import image\n",
    "from nilearn import plotting\n",
    "from nilearn.plotting import plot_stat_map, plot_anat, plot_img, show\n",
    "from numpy import nan as NaN\n",
    "from os import listdir as ls\n",
    "from os.path import basename as bname\n",
    "from os.path import dirname as dname\n",
    "from os.path import join\n",
    "from pandas import DataFrame as df\n",
    "from cimaq_utils import loadimages\n",
    "from get_new_events import get_new_events\n",
    "from pandas import DataFrame as df\n",
    "\n",
    "def main():\n",
    "    \n",
    "    def get_new_events(taskfilesdir, outTask_dir, savefiles=False):\n",
    "        #rename \"trial_type\" column as \"condition\"\n",
    "        taskfiles = [(os.path.splitext(bname(file))[0], pd.read_csv(join(taskfilesdir, file), sep='\\t'))\n",
    "                     for file in ls(taskfilesdir) if \"events\" in file and file.endswith(\".tsv\")]\n",
    "        new_events = []\n",
    "\n",
    "        for s_task in taskfiles:\n",
    "        #load counfounds file as pandas dataframe \n",
    "        # confounds = pd.read_csv(subject_motion, sep='\\t')\n",
    "        #scan duration, in seconds : number of fMRI frames (~310), times TR = 2.5s\n",
    "        # scanDur = confounds.shape[0]*2.5\n",
    "            scanDur = s_task[1].shape[0]*2.5\n",
    "\n",
    "            s_task[1].rename(columns={'trial_type':'condition'}, inplace=True)\n",
    "\n",
    "            #add columns to DataFrame\n",
    "            numCol = s_task[1].shape[1] \n",
    "            insertCol = [4, numCol+1, numCol+2, numCol+3]\n",
    "            colNames = ['trial_type', 'unscanned', 'ctl_miss_hit', 'ctl_miss_ws_cs']\n",
    "            colVals = ['TBD', 0, 'TBD', 'TBD']\n",
    "            for i in range(0, len(colNames)):\n",
    "                s_task[1].insert(loc=insertCol[i], column=colNames[i], value=colVals[i], allow_duplicates=True)\n",
    "\n",
    "            #The 'unscanned' column flag trials for which no brain data was acquired.\n",
    "            #The scan's duration is shorter than the trial's offset time\n",
    "            #(0 = data, 1 = no data)\n",
    "            for j in s_task[1][s_task[1]['offset']>scanDur].index:\n",
    "                s_task[1].loc[j, 'unscanned']=1\n",
    "\n",
    "            #pas trial numbers with zeros (on the left) to preserve trial \n",
    "            #temporal order when trials are alphabetized\n",
    "            s_task[1]['trial_number'] = s_task[1]['trial_number'].astype('object',\n",
    "                                                                   copy=False)\n",
    "            for k in s_task[1].index:\n",
    "                s_task[1].loc[k, 'trial_number'] = str(s_task[1].loc[k, 'trial_number']).zfill(3)\n",
    "\n",
    "            #trial_type should have a unique entry per row so that each trial \n",
    "            #can be modelled as a separate condition\n",
    "            countEnc = 0\n",
    "            countCTL = 0\n",
    "            for m in s_task[1][s_task[1]['condition']=='Enc'].index:\n",
    "                countEnc = countEnc + 1\n",
    "                s_task[1].loc[m, 'trial_type'] = 'Enc'+str(countEnc)\n",
    "                if s_task[1].loc[m, 'position_accuracy'] == 0:\n",
    "                    s_task[1].loc[m, 'ctl_miss_hit']='missed'\n",
    "                    s_task[1].loc[m, 'ctl_miss_ws_cs']='missed'\n",
    "                elif s_task[1].loc[m, 'position_accuracy'] == 1:\n",
    "                    s_task[1].loc[m, 'ctl_miss_hit']='hit'\n",
    "                    s_task[1].loc[m, 'ctl_miss_ws_cs']='wrongsource'\n",
    "                elif s_task[1].loc[m, 'position_accuracy'] == 2:\n",
    "                    s_task[1].loc[m, 'ctl_miss_hit']='hit'\n",
    "                    s_task[1].loc[m, 'ctl_miss_ws_cs']='correctsource' \n",
    "            for n in s_task[1][s_task[1]['condition']=='CTL'].index:\n",
    "                countCTL = countCTL + 1\n",
    "                s_task[1].loc[n, 'trial_type'] = 'CTL'+str(countCTL)\n",
    "                s_task[1].loc[n, 'ctl_miss_hit']='control'\n",
    "                s_task[1].loc[n, 'ctl_miss_ws_cs']='control'\n",
    "\n",
    "            #78 encoding and 39 control trials if full scan\n",
    "            print('Number of encoding trials:  ', countEnc)\n",
    "            print('Number of control trials:  ', countCTL)\n",
    "\n",
    "\n",
    "\n",
    "            #keep only trials for which fMRI data was collected\n",
    "    # #        s_task[1] = s_task[1][s_task[1]['unscanned']==0]\n",
    "\n",
    "            s_task[1]['unscanned'] = 0\n",
    "\n",
    "            #Save vectors of trial labels (e.g., encoding vs control)\n",
    "            #to label trials for classification analyses\n",
    "            ttypes1 = s_task[1]['condition']\n",
    "            \n",
    "            # Allows user to overwrite files to disk or not \n",
    "            \n",
    "            if not savefiles:\n",
    "                        #Export Dataframe to events.tsv file    \n",
    "                s_task[1].to_csv(outTask_dir+'/sub-'+id+'_events.tsv',\n",
    "                              sep='\\t', header=True, index=False)\n",
    "                ttypes1.to_csv(outTask_dir+'/sub-'+id+'_enco_ctl.tsv',\n",
    "                               sep='\\t', header=True, index=False)\n",
    "                ttypes2.to_csv(outTask_dir+'/sub-'+id+'_ctl_miss_hit.tsv',\n",
    "                               sep='\\t', header=True, index=False)\n",
    "                ttypes3.to_csv(outTask_dir+'/sub-'+id+'_ctl_miss_ws_cs.tsv',\n",
    "                               sep='\\t', header=True, index=False)\n",
    "\n",
    "            ttypes2 = s_task[1]['ctl_miss_hit']\n",
    "\n",
    "\n",
    "            ttypes3 = s_task[1]['ctl_miss_ws_cs']\n",
    "\n",
    "\n",
    "            new_events.append([(s_task[0], s_task[1]), ttypes1, ttypes2, ttypes3])\n",
    "        #from s_task[1] dataframe, create an events dataframe to create a design matrix \n",
    "        #that will be inputed into a first-level model in nistats\n",
    "        ev_cols = ['onset', 'duration', 'trial_type', 'condition', 'ctl_miss_hit', \n",
    "                   'ctl_miss_ws_cs', 'trial_number']\n",
    "        all_events = s_task[1][ev_cols]\n",
    "        return new_events, all_events\n",
    "    \n",
    "    get_new_events(taskfilesdir, outTask_dir)\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
