{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['albinos.jpg']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import csv\n",
    "import json\n",
    "import nilearn\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import random\n",
    "import regex as re\n",
    "import string\n",
    "import struct\n",
    "import sys\n",
    "\n",
    "from chardet import UniversalDetector as udet\n",
    "from io import StringIO\n",
    "from os.path import basename as bname\n",
    "from os.path import dirname as dname\n",
    "from os.path import expanduser as xpu\n",
    "from os import listdir as ls\n",
    "from os.path import join as pjoin\n",
    "from pandas import DataFrame as df\n",
    "from string import printable\n",
    "from typing import Union\n",
    "from zipfile import ZipFile\n",
    "from tqdm import tqdm\n",
    "from unidecode import unidecode\n",
    "\n",
    "from cimaq_utils import get_cimaq_dir_paths\n",
    "from sniffbytes import flatten\n",
    "from sniffbytes import loadfiles\n",
    "from sniffbytes import loadimages\n",
    "from cimaq_utils import repair_enc_task\n",
    "from cimaq_utils import fetch_cimaq\n",
    "\n",
    "from json_read import json_read\n",
    "\n",
    "import sniffbytes as snif\n",
    "from get_zip_contents import get_zip_contents\n",
    "\n",
    "from removeEmptyFolders import removeEmptyFolders\n",
    "from multiple_replace import multiple_replace\n",
    "cimaq_dir = '~/../../media/francois/seagate_1tb/cimaq_03-19/cimaq_03-19/derivatives/CIMAQ_fmri_memory/data/task_files/zipped_eprime'\n",
    "# cimaq_dir = '~/../../media/francois/seagate_1tb/cimaq_03-19/cimaq_03-19/derivatives/CIMAQ_fmri_memory/data'\n",
    "# cimaq_dir = '~/../../media/francois/seagate_1tb/old_cimaq_03-19/cimaq_derivatives'\n",
    "otherdir = '/home/fnadeau/projects/rrg-pbellec/fnadeau/cimaq_03-19/cimaq_03-19/sub-127228/ses-4/anat'\n",
    "dlst = get_cimaq_dir_paths(cimaq_dir)[0]#[['confdir', 'events_dir']]\n",
    "\n",
    "loadimages(xpu(cimaq_dir))\n",
    "alist = ['albinos.jpg', 'data.pdf', 'newday.tar.xz']\n",
    "\n",
    "snif.filter_lst_exc(['.jpg'], alist)\n",
    "snif.filter_lst_inc(['.jpg'], alist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nice_xtrct(archv_path: Union[os.PathLike, str],\n",
    "    ntpl: Union[str, list, tuple] = None,\n",
    "    to_xtrct: Union[str, list, tuple] = 'all',\n",
    "    exclude: Union[str, list, tuple] = [],\n",
    "    to_close: bool = True,\n",
    "    withbytes: bool = False,\n",
    "    dst_path: Union[os.PathLike, str] = None) -> object:\n",
    "    dst_path = [dst_path if dst_path\n",
    "                else pjoin(os.get_cwd(),\n",
    "                           os.path.splitext(bname(archv_path))[0])][0]\n",
    "    os.makedirs(dst_path, exist_ok=True)\n",
    "    myzip = zipfile.ZipFile(archv_path)\n",
    "    ntpl = filter_lst_exc([ntpl if ntpl else getnametuple(myzip)][0])\n",
    "    contents = get_zip_contents(archv_path, ntpl, excllude, to_xtrct,\n",
    "                                to_close = True, withbytes = True, to_sniff = True)\n",
    "    xtrct_lst = vals.loc[\n",
    "        [\n",
    "            row[0]\n",
    "            for row in vals.iterrows()\n",
    "            if row[1].filename\n",
    "            in filter_lst_inc(to_xtrct, list(vals.filename), sort=True)\n",
    "        ]\n",
    "    ]\n",
    "    [\n",
    "        shutil.move(\n",
    "            myzip.extract(member=row[1].src_name, path=dst_path),\n",
    "            pjoin(\n",
    "                dst_path,\n",
    "                \"_\".join(\n",
    "                    pd.Series(\n",
    "                        row[1].filename.lower().replace(\"-\", \"_\").split(\"_\")\n",
    "                    ).unique()\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        for row in tqdm(xtrct_lst.iterrows(), desc=\"extracting\")\n",
    "    ]\n",
    "    vals = vals.loc[\n",
    "        [\n",
    "            row[0]\n",
    "            for row in vals.iterrows()\n",
    "            if row[1].filename not in xtrct_lst.values\n",
    "        ]\n",
    "    ]\n",
    "    removeEmptyFolders(dst_path, False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21511"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b_printables = [chr(int.from_bytes(itm.encode(), sys.byteorder)).encode() for itm in string.printable]\n",
    "str(b_printables[-1]) == repr(b_printables[-1])\n",
    "\n",
    "def force_to(inpt, src_enc: str = None, dst_enc: str = 'utf8'):\n",
    "    inpt = get_bytes(inpt)\n",
    "    as_ints = [[line.split()]]\n",
    "    \n",
    "    \n",
    "chr(list(asheet)[0])\n",
    "list(asheet).__len__()\n",
    "# chr(int.from_bytes(b_printables[-1], sys.byteorder))\n",
    "\n",
    "# [chr(itm) for itm in list(asheet)]\n",
    "# help(chr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "chr() arg not in range(0x110000)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-27c47c079699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#                            for row in big.iterrows()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m'\\\\x0'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf16'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb\"\\0xf\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbyteorder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: chr() arg not in range(0x110000)"
     ]
    }
   ],
   "source": [
    "# cimaq_topdir = '~/../../media/francois/seagate_1tb/cimaq_03-19/cimaq_03-19/derivatives/'\n",
    "# big = loadfiles([apath for apath in loadimages(xpu(cimaq_topdir))\n",
    "#                  if os.path.isfile(apath)])\n",
    "# big[['dccid', 'pscid']] = [([re.compile('\\d{6}').search(row[1].fname).group()\n",
    "#                              if re.compile('\\d{6}').search(row[1].fname) != None\n",
    "#                              else None][0],\n",
    "#                             [re.compile('\\d{7}').search(row[1].fname).group()\n",
    "#                              if re.compile('\\d{7}').search(row[1].fname) != None\n",
    "#                              else None][0])\n",
    "#                            for row in big.iterrows()]\n",
    "'\\\\x0'.encode('utf16')\n",
    "chr(int.from_bytes(b\"\\0xff\", sys.byteorder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scan sniff concat: 100%|██████████| 103/103 [00:08<00:00, 11.68it/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# test2 = pd.concat([itm[1] for itm in tqdm(sorted(list(test)), desc = 'concatenate')])\n",
    "\n",
    "# test2['forced_utf8'] = [snif.force_utf8(row[1].bsheets, row[1].encoding)\n",
    "#                         for row in test2.iterrows()]\n",
    "\n",
    "#.filename,\n",
    "#                    snif.scan_bytes(row[1].forced_utf8, encoding='utf'))\n",
    "#                         for row in itm[1].iterrows())\n",
    "#              for itm in tqdm(list(test.items()),  desc = 'scan & sniff utf8')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test =  dict((bname(apath.replace('-', '_').strip()),\n",
    "                    get_zip_contents(apath, withbytes = True,\n",
    "                         to_sniff = True, to_close = True))\n",
    "                    for apath in tqdm(loadimages(xpu(cimaq_dir)),\n",
    "                          desc = 'scan sniff'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'subject' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7e0f681216af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                        (('pscid', 'dccid'), row[1].filename.split('_')[:2])])),\n\u001b[1;32m      7\u001b[0m                              orient = 'index'))\n\u001b[0;32m----> 8\u001b[0;31m                for row in tqdm(subject[1].iterrows(), desc = 'new sniff'))\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'subject' is not defined"
     ]
    }
   ],
   "source": [
    "newtest = dict((subject[0], \n",
    "                df.from_dict(dict((itm for itm in\n",
    "                                   list(snif.scan_bytes(snif.force_utf8(\n",
    "                  row[1].bsheets, row[1].encoding)).items()) + \\\n",
    "                      [('filename', row[1].filename),\n",
    "                       (('pscid', 'dccid'), row[1].filename.split('_')[:2])])),\n",
    "                             orient = 'index'))\n",
    "               for row in tqdm(subject[1].iterrows(), desc = 'new sniff'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('3025432_658178_Tache_IRM.zip',\n",
       "                                             filename compress_type  \\\n",
       " 0                3025432_658178_tache_irm_658178.pdf       deflate   \n",
       " 1     3025432_658178_tache_irm_encoding_scan_1.edat2       deflate   \n",
       " 2  3025432_658178_tache_irm_onset_event_encoding_...       deflate   \n",
       " 3  3025432_658178_tache_irm_output_responses_enco...       deflate   \n",
       " 4  3025432_658178_tache_irm_output_retrieval_cima...       deflate   \n",
       " 5          3025432_658178_tache_irm_pratique_1.edat2       deflate   \n",
       " 6            3025432_658178_tache_irm_pratique_1.txt       deflate   \n",
       " 7         3025432_658178_tache_irm_retrieval_1.edat2       deflate   \n",
       " 8           3025432_658178_tache_irm_retrieval_1.txt       deflate   \n",
       " \n",
       "      filemode external_attr file_size compress_size  \\\n",
       " 0  -rw-r--r--        0x4000    354022        339482   \n",
       " 1  -rwxrwxrwx        0x4000     94208         13382   \n",
       " 2  -rwxrwxrwx        0x4000     21511          3011   \n",
       " 3  -rwxrwxrwx        0x4000      3557          1206   \n",
       " 4  -rwxrwxrwx        0x4000      5816          2174   \n",
       " 5  -rwxrwxrwx        0x4000     41472          5946   \n",
       " 6  -rwxrwxrwx        0x4000     67784          4463   \n",
       " 7  -rwxrwxrwx        0x4000     52224          7218   \n",
       " 8  -rwxrwxrwx        0x4000    126838          6016   \n",
       " \n",
       "                                             src_name     ext  \\\n",
       " 0        3025432_658178_Tache_IRM/3025432_658178.pdf    .pdf   \n",
       " 1  3025432_658178_Tache_IRM/Encoding-scan-3025432...  .edat2   \n",
       " 2  3025432_658178_Tache_IRM/Onset-Event-Encoding_...    .txt   \n",
       " 3  3025432_658178_Tache_IRM/Output-Responses-Enco...    .txt   \n",
       " 4  3025432_658178_Tache_IRM/Output_Retrieval_CIMA...    .txt   \n",
       " 5  3025432_658178_Tache_IRM/PRATIQUE-3025432-1.edat2  .edat2   \n",
       " 6    3025432_658178_Tache_IRM/PRATIQUE-3025432-1.txt    .txt   \n",
       " 7  3025432_658178_Tache_IRM/Retrieval-3025432-1.e...  .edat2   \n",
       " 8   3025432_658178_Tache_IRM/Retrieval-3025432-1.txt    .txt   \n",
       " \n",
       "                                              bsheets      encoding  \\\n",
       " 0  b'%pdf-1.4\\n%\\xf8\\xe5\\xd0\\xc4\\xc6\\n1 0 obj\\n<<...         ascii   \n",
       " 1  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...  Windows-1252   \n",
       " 2  b'1             ctl           ctl0            ...         ascii   \n",
       " 3  b'trialnumber\\tcategory\\ttrialcode\\toldnumber\\...         ascii   \n",
       " 4  b'category\\tstim\\toldnumber\\trecognition_acc\\t...    ISO-8859-1   \n",
       " 5  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...    ISO-8859-1   \n",
       " 6  b'\\xff\\xfe*\\x00*\\x00*\\x00 \\x00h\\x00e\\x00a\\x00d...        UTF-16   \n",
       " 7  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...    ISO-8859-1   \n",
       " 8  b'\\xff\\xfe*\\x00*\\x00*\\x00 \\x00h\\x00e\\x00a\\x00d...        UTF-16   \n",
       " \n",
       "           delimiter  has_header  width  dup_index  nrows  \n",
       " 0               b''        True    977      False   3893  \n",
       " 1       b'no entry'        True    705      False    386  \n",
       " 2  b'             '       False     90       True    240  \n",
       " 3             b'\\t'        True     30      False    121  \n",
       " 4             b'\\t'        True     57      False    118  \n",
       " 5       b'no entry'        True    697      False    244  \n",
       " 6       b'no entry'       False   1067      False   2697  \n",
       " 7       b'no entry'        True    665      False    346  \n",
       " 8       b'no entry'       False   1069      False   5489  )"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(test.items())[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\xdd\\xae'"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert newtest.loc['encoding'].all() == 'ascii' or 'UTF-8'\n",
    "chr(int.from_bytes('n\\a'.encode(), sys.byteorder))\n",
    "\n",
    "b'n\\a' == 'n\\a'.encode()\n",
    "\n",
    "chr(int.from_bytes('n\\a'.encode(), sys.byteorder)).encode('utf8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def last_item(inpt: bytes, encoding: str = None) -> bytes:\n",
    "    ''' Returns null byte representation as bytes in native file encoding'''\n",
    "    encoding = [encoding if encoding else snif.get_bencod(inpt)][0]\n",
    "#     return bytes([inpt.splitlines(keepends = True)[-1][-1]]).decode(encoding).encode(encoding)\n",
    "#     rep = chr(list(inpt)[-1]).encode(encoding)\n",
    "    last1 = inpt.splitlines()[-1].split()[-1]\n",
    "    last2 = [chr(itm).encode(encoding) for itm in\n",
    "             list(chr(list(inpt.splitlines()[-1])[-1]).encode(encoding))]\n",
    "    return (last1, last2)\n",
    "#     return [chr(itm) for itm in list(chr(list(inpt.splitlines()[-1])[-1]).encode(encoding))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                                            filename compress_type  \\\n",
       " 0     8330218_413474_tache_irm_encoding_scan_1.edat2       deflate   \n",
       " 1       8330218_413474_tache_irm_encoding_scan_1.txt       deflate   \n",
       " 2  8330218_413474_tache_irm_onset_event_encoding_...       deflate   \n",
       " 3  8330218_413474_tache_irm_output_responses_enco...       deflate   \n",
       " 4  8330218_413474_tache_irm_output_retrieval_cima...       deflate   \n",
       " 5          8330218_413474_tache_irm_pratique_1.edat2       deflate   \n",
       " 6            8330218_413474_tache_irm_pratique_1.txt       deflate   \n",
       " 7         8330218_413474_tache_irm_retrieval_1.edat2       deflate   \n",
       " 8           8330218_413474_tache_irm_retrieval_1.txt       deflate   \n",
       " \n",
       "      filemode external_attr file_size compress_size  \\\n",
       " 0  -rwxrwxrwx        0x4000     94208         13338   \n",
       " 1  -rwxrwxrwx        0x4000    206368         13044   \n",
       " 2  -rwxrwxrwx        0x4000     21511          3023   \n",
       " 3  -rwxrwxrwx        0x4000      3551          1196   \n",
       " 4  -rwxrwxrwx        0x4000      5908          2206   \n",
       " 5  -rwxrwxrwx        0x4000     41472          5905   \n",
       " 6  -rwxrwxrwx        0x4000     67904          4436   \n",
       " 7  -rwxrwxrwx        0x4000     52224          7209   \n",
       " 8  -rwxrwxrwx        0x4000    127026          6081   \n",
       " \n",
       "                                             src_name     ext  \\\n",
       " 0  8330218_413474_Tache_IRM/Encoding-scan-8330218...  .edat2   \n",
       " 1  8330218_413474_Tache_IRM/Encoding-scan-8330218...    .txt   \n",
       " 2  8330218_413474_Tache_IRM/Onset-Event-Encoding_...    .txt   \n",
       " 3  8330218_413474_Tache_IRM/Output-Responses-Enco...    .txt   \n",
       " 4  8330218_413474_Tache_IRM/Output_Retrieval_CIMA...    .txt   \n",
       " 5  8330218_413474_Tache_IRM/PRATIQUE-8330218-1.edat2  .edat2   \n",
       " 6    8330218_413474_Tache_IRM/PRATIQUE-8330218-1.txt    .txt   \n",
       " 7  8330218_413474_Tache_IRM/Retrieval-8330218-1.e...  .edat2   \n",
       " 8   8330218_413474_Tache_IRM/Retrieval-8330218-1.txt    .txt   \n",
       " \n",
       "                                              bsheets      encoding  \\\n",
       " 0  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...  Windows-1252   \n",
       " 1  b'\\xff\\xfe*\\x00*\\x00*\\x00 \\x00h\\x00e\\x00a\\x00d...        UTF-16   \n",
       " 2  b'1             ctl           ctl0            ...         ascii   \n",
       " 3  b'trialnumber\\tcategory\\ttrialcode\\toldnumber\\...         ascii   \n",
       " 4  b'category\\tstim\\toldnumber\\trecognition_acc\\t...    ISO-8859-1   \n",
       " 5  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...    ISO-8859-1   \n",
       " 6  b'\\xff\\xfe*\\x00*\\x00*\\x00 \\x00h\\x00e\\x00a\\x00d...        UTF-16   \n",
       " 7  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...    ISO-8859-1   \n",
       " 8  b'\\xff\\xfe*\\x00*\\x00*\\x00 \\x00h\\x00e\\x00a\\x00d...        UTF-16   \n",
       " \n",
       "           delimiter  has_header  width  dup_index  nrows  \n",
       " 0       b'no entry'        True    776      False    385  \n",
       " 1       b'no entry'       False   1075      False   9623  \n",
       " 2  b'             '       False     90       True    240  \n",
       " 3             b'\\t'        True     30      False    121  \n",
       " 4             b'\\t'        True     57      False    118  \n",
       " 5       b'no entry'        True    697      False    242  \n",
       " 6       b'no entry'       False   1065      False   2695  \n",
       " 7       b'no entry'        True    561      False    347  \n",
       " 8       b'no entry'       False   1069      False   5489  ]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list(chr(int.from_bytes(b'\\x00', sys.byteorder)))\n",
    "# snif.get_bencod(chr(0))\n",
    "int.from_bytes(b'\\x00', sys.byteorder)\n",
    "aguy = random.sample(list(test.values()), 1)\n",
    "aguy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>compress_type</th>\n",
       "      <th>filemode</th>\n",
       "      <th>external_attr</th>\n",
       "      <th>file_size</th>\n",
       "      <th>compress_size</th>\n",
       "      <th>src_name</th>\n",
       "      <th>ext</th>\n",
       "      <th>bsheets</th>\n",
       "      <th>encoding</th>\n",
       "      <th>...</th>\n",
       "      <th>sheet_diff_bothalf</th>\n",
       "      <th>nrows_test</th>\n",
       "      <th>utf8len</th>\n",
       "      <th>missing_line</th>\n",
       "      <th>missing_line_index</th>\n",
       "      <th>missing_line_values</th>\n",
       "      <th>nbytes_check</th>\n",
       "      <th>n_zbytes</th>\n",
       "      <th>n_scanbytes</th>\n",
       "      <th>chkup</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3025432_658178_tache_irm_658178.pdf</td>\n",
       "      <td>deflate</td>\n",
       "      <td>-rw-r--r--</td>\n",
       "      <td>0x4000</td>\n",
       "      <td>354022</td>\n",
       "      <td>339482</td>\n",
       "      <td>3025432_658178_Tache_IRM/3025432_658178.pdf</td>\n",
       "      <td>.pdf</td>\n",
       "      <td>b'%pdf-1.4\\n%\\xf8\\xe5\\xd0\\xc4\\xc6\\n1 0 obj\\n&lt;&lt;...</td>\n",
       "      <td>ascii</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>3893</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>354022</td>\n",
       "      <td>354022</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3025432_658178_tache_irm_encoding_scan_1.edat2</td>\n",
       "      <td>deflate</td>\n",
       "      <td>-rwxrwxrwx</td>\n",
       "      <td>0x4000</td>\n",
       "      <td>94208</td>\n",
       "      <td>13382</td>\n",
       "      <td>3025432_658178_Tache_IRM/Encoding-scan-3025432...</td>\n",
       "      <td>.edat2</td>\n",
       "      <td>b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...</td>\n",
       "      <td>Windows-1252</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>386</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>94208</td>\n",
       "      <td>94208</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3025432_658178_tache_irm_onset_event_encoding_...</td>\n",
       "      <td>deflate</td>\n",
       "      <td>-rwxrwxrwx</td>\n",
       "      <td>0x4000</td>\n",
       "      <td>21511</td>\n",
       "      <td>3011</td>\n",
       "      <td>3025432_658178_Tache_IRM/Onset-Event-Encoding_...</td>\n",
       "      <td>.txt</td>\n",
       "      <td>b'1             ctl           ctl0            ...</td>\n",
       "      <td>ascii</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>240</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>21511</td>\n",
       "      <td>21511</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3025432_658178_tache_irm_output_responses_enco...</td>\n",
       "      <td>deflate</td>\n",
       "      <td>-rwxrwxrwx</td>\n",
       "      <td>0x4000</td>\n",
       "      <td>3557</td>\n",
       "      <td>1206</td>\n",
       "      <td>3025432_658178_Tache_IRM/Output-Responses-Enco...</td>\n",
       "      <td>.txt</td>\n",
       "      <td>b'trialnumber\\tcategory\\ttrialcode\\toldnumber\\...</td>\n",
       "      <td>ascii</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>121</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>3557</td>\n",
       "      <td>3557</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3025432_658178_tache_irm_output_retrieval_cima...</td>\n",
       "      <td>deflate</td>\n",
       "      <td>-rwxrwxrwx</td>\n",
       "      <td>0x4000</td>\n",
       "      <td>5816</td>\n",
       "      <td>2174</td>\n",
       "      <td>3025432_658178_Tache_IRM/Output_Retrieval_CIMA...</td>\n",
       "      <td>.txt</td>\n",
       "      <td>b'category\\tstim\\toldnumber\\trecognition_acc\\t...</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>118</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>5816</td>\n",
       "      <td>5816</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3025432_658178_tache_irm_pratique_1.edat2</td>\n",
       "      <td>deflate</td>\n",
       "      <td>-rwxrwxrwx</td>\n",
       "      <td>0x4000</td>\n",
       "      <td>41472</td>\n",
       "      <td>5946</td>\n",
       "      <td>3025432_658178_Tache_IRM/PRATIQUE-3025432-1.edat2</td>\n",
       "      <td>.edat2</td>\n",
       "      <td>b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>243</td>\n",
       "      <td>[(0, b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x0...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>41472</td>\n",
       "      <td>41472</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3025432_658178_tache_irm_pratique_1.txt</td>\n",
       "      <td>deflate</td>\n",
       "      <td>-rwxrwxrwx</td>\n",
       "      <td>0x4000</td>\n",
       "      <td>67784</td>\n",
       "      <td>4463</td>\n",
       "      <td>3025432_658178_Tache_IRM/PRATIQUE-3025432-1.txt</td>\n",
       "      <td>.txt</td>\n",
       "      <td>b'\\xff\\xfe*\\x00*\\x00*\\x00 \\x00h\\x00e\\x00a\\x00d...</td>\n",
       "      <td>UTF-16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>2697</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>67784</td>\n",
       "      <td>67784</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3025432_658178_tache_irm_retrieval_1.edat2</td>\n",
       "      <td>deflate</td>\n",
       "      <td>-rwxrwxrwx</td>\n",
       "      <td>0x4000</td>\n",
       "      <td>52224</td>\n",
       "      <td>7218</td>\n",
       "      <td>3025432_658178_Tache_IRM/Retrieval-3025432-1.e...</td>\n",
       "      <td>.edat2</td>\n",
       "      <td>b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...</td>\n",
       "      <td>ISO-8859-1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>346</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>52224</td>\n",
       "      <td>52224</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>3025432_658178_tache_irm_retrieval_1.txt</td>\n",
       "      <td>deflate</td>\n",
       "      <td>-rwxrwxrwx</td>\n",
       "      <td>0x4000</td>\n",
       "      <td>126838</td>\n",
       "      <td>6016</td>\n",
       "      <td>3025432_658178_Tache_IRM/Retrieval-3025432-1.txt</td>\n",
       "      <td>.txt</td>\n",
       "      <td>b'\\xff\\xfe*\\x00*\\x00*\\x00 \\x00h\\x00e\\x00a\\x00d...</td>\n",
       "      <td>UTF-16</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>5489</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>126838</td>\n",
       "      <td>126838</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            filename compress_type  \\\n",
       "0                3025432_658178_tache_irm_658178.pdf       deflate   \n",
       "1     3025432_658178_tache_irm_encoding_scan_1.edat2       deflate   \n",
       "2  3025432_658178_tache_irm_onset_event_encoding_...       deflate   \n",
       "3  3025432_658178_tache_irm_output_responses_enco...       deflate   \n",
       "4  3025432_658178_tache_irm_output_retrieval_cima...       deflate   \n",
       "5          3025432_658178_tache_irm_pratique_1.edat2       deflate   \n",
       "6            3025432_658178_tache_irm_pratique_1.txt       deflate   \n",
       "7         3025432_658178_tache_irm_retrieval_1.edat2       deflate   \n",
       "8           3025432_658178_tache_irm_retrieval_1.txt       deflate   \n",
       "\n",
       "     filemode external_attr file_size compress_size  \\\n",
       "0  -rw-r--r--        0x4000    354022        339482   \n",
       "1  -rwxrwxrwx        0x4000     94208         13382   \n",
       "2  -rwxrwxrwx        0x4000     21511          3011   \n",
       "3  -rwxrwxrwx        0x4000      3557          1206   \n",
       "4  -rwxrwxrwx        0x4000      5816          2174   \n",
       "5  -rwxrwxrwx        0x4000     41472          5946   \n",
       "6  -rwxrwxrwx        0x4000     67784          4463   \n",
       "7  -rwxrwxrwx        0x4000     52224          7218   \n",
       "8  -rwxrwxrwx        0x4000    126838          6016   \n",
       "\n",
       "                                            src_name     ext  \\\n",
       "0        3025432_658178_Tache_IRM/3025432_658178.pdf    .pdf   \n",
       "1  3025432_658178_Tache_IRM/Encoding-scan-3025432...  .edat2   \n",
       "2  3025432_658178_Tache_IRM/Onset-Event-Encoding_...    .txt   \n",
       "3  3025432_658178_Tache_IRM/Output-Responses-Enco...    .txt   \n",
       "4  3025432_658178_Tache_IRM/Output_Retrieval_CIMA...    .txt   \n",
       "5  3025432_658178_Tache_IRM/PRATIQUE-3025432-1.edat2  .edat2   \n",
       "6    3025432_658178_Tache_IRM/PRATIQUE-3025432-1.txt    .txt   \n",
       "7  3025432_658178_Tache_IRM/Retrieval-3025432-1.e...  .edat2   \n",
       "8   3025432_658178_Tache_IRM/Retrieval-3025432-1.txt    .txt   \n",
       "\n",
       "                                             bsheets      encoding  ...  \\\n",
       "0  b'%pdf-1.4\\n%\\xf8\\xe5\\xd0\\xc4\\xc6\\n1 0 obj\\n<<...         ascii  ...   \n",
       "1  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...  Windows-1252  ...   \n",
       "2  b'1             ctl           ctl0            ...         ascii  ...   \n",
       "3  b'trialnumber\\tcategory\\ttrialcode\\toldnumber\\...         ascii  ...   \n",
       "4  b'category\\tstim\\toldnumber\\trecognition_acc\\t...    ISO-8859-1  ...   \n",
       "5  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...    ISO-8859-1  ...   \n",
       "6  b'\\xff\\xfe*\\x00*\\x00*\\x00 \\x00h\\x00e\\x00a\\x00d...        UTF-16  ...   \n",
       "7  b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x00\\x00...    ISO-8859-1  ...   \n",
       "8  b'\\xff\\xfe*\\x00*\\x00*\\x00 \\x00h\\x00e\\x00a\\x00d...        UTF-16  ...   \n",
       "\n",
       "  sheet_diff_bothalf  nrows_test  utf8len  \\\n",
       "0              False        True     3893   \n",
       "1              False        True      386   \n",
       "2              False        True      240   \n",
       "3              False        True      121   \n",
       "4              False        True      118   \n",
       "5              False       False      243   \n",
       "6              False        True     2697   \n",
       "7              False        True      346   \n",
       "8              False        True     5489   \n",
       "\n",
       "                                        missing_line  missing_line_index  \\\n",
       "0                                               True                 NaN   \n",
       "1                                               True                 NaN   \n",
       "2                                               True                 NaN   \n",
       "3                                               True                 NaN   \n",
       "4                                               True                 NaN   \n",
       "5  [(0, b'\\xd0\\xcf\\x11\\xe0\\xa1\\xb1\\x1a\\xe1\\x00\\x0...                 NaN   \n",
       "6                                               True                 NaN   \n",
       "7                                               True                 NaN   \n",
       "8                                               True                 NaN   \n",
       "\n",
       "   missing_line_values nbytes_check n_zbytes n_scanbytes  chkup  \n",
       "0                  NaN        False   354022      354022   True  \n",
       "1                  NaN        False    94208       94208   True  \n",
       "2                  NaN        False    21511       21511   True  \n",
       "3                  NaN        False     3557        3557   True  \n",
       "4                  NaN        False     5816        5816   True  \n",
       "5                  NaN        False    41472       41472   True  \n",
       "6                  NaN        False    67784       67784   True  \n",
       "7                  NaN        False    52224       52224   True  \n",
       "8                  NaN        False   126838      126838   True  \n",
       "\n",
       "[9 rows x 30 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aguy = list(test.values())[0]\n",
    "aguy['size_check'] = [int(row[1].file_size) == len(list(row[1].bsheets))\n",
    "                      for row in aguy.iterrows()]\n",
    "aguy['na_reps'] = [snif.get_nullrep(row[1].bsheets) for row in aguy.iterrows()]\n",
    "aguy['last_item'] = [last_item(row[1].bsheets, row[1].encoding) for row in aguy.iterrows()]\n",
    "\n",
    "aguy[['n_zbytes', 'n_scanbytes', 'chkup']] = [(int(len(list(row[1].bsheets))), int(row[1].file_size),\n",
    "                                      (int(len(list(row[1].bsheets))) == int(row[1].file_size)))\n",
    "                                     for row in aguy.iterrows()]\n",
    "aguy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/francois/.local/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Must have equal len keys and value when setting with an iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-129-8027d1c8e9e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m aguy['nrows_test'] = [(len(row[1].bsheets.splitlines()) == len(row[1].forced_utf8.splitlines()))\n\u001b[1;32m     16\u001b[0m                       for row in aguy.iterrows()]\n\u001b[0;32m---> 17\u001b[0;31m aguy[['missing_line_index', 'missing_line_values']] = [(row[1].nrows_test)*2 if row[1].nrows_test else\n\u001b[0m\u001b[1;32m     18\u001b[0m                         sorted([(line[0], line[1]) for line in enumerate(row[1].bsheets.splitlines()) if\n\u001b[1;32m     19\u001b[0m                                 snif.force_utf8(line[1], 'utf8') not in row[1].forced_utf8.splitlines()])\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3159\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3160\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3161\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3162\u001b[0m             \u001b[0;31m# set column\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_setitem_array\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   3193\u001b[0m                 )[1]\n\u001b[1;32m   3194\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_setitem_copy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3195\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3197\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_setitem_frame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0miloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iloc\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0miloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtake_split_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1634\u001b[0m             \u001b[0;31m# We have to operate column-wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_with_indexer_split_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setitem_single_block\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_setitem_with_indexer_split_path\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1710\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1711\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1712\u001b[0m                     \u001b[0;34m\"Must have equal len keys and value \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1713\u001b[0m                     \u001b[0;34m\"when setting with an iterable\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Must have equal len keys and value when setting with an iterable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "aguy['utf8len'] = [len(row[1].forced_utf8.splitlines()) for row in aguy.iterrows()]\n",
    "aguy['sheet_diff_tophalf'] = [row[1].bsheets.splitlines()[:int(np.floor(len(\n",
    "                                 row[1].bsheets.splitlines())/2))] == \\\n",
    "                                 row[1].forced_utf8.splitlines()[int(np.floor(len(\n",
    "                                     row[1].bsheets.splitlines())/2)):]\n",
    "                              for row in aguy.iterrows()]\n",
    "aguy['sheet_diff_bothalf'] = [[line.strip() for line in\n",
    "                               row[1].bsheets.splitlines()[:int(np.floor(len(\n",
    "                                 row[1].bsheets.splitlines())/2))]] == \\\n",
    "                                 [line.strip() for line in\n",
    "                                  row[1].forced_utf8.splitlines()[int(np.floor(len(\n",
    "                                     row[1].bsheets.splitlines())/2)):]]\n",
    "                              for row in aguy.iterrows()]\n",
    "\n",
    "aguy['nrows_test'] = [(len(row[1].bsheets.splitlines()) == len(row[1].forced_utf8.splitlines()))\n",
    "                      for row in aguy.iterrows()]\n",
    "aguy[['missing_line_index', 'missing_line_values']] = [(row[1].nrows_test)*2 if row[1].nrows_test else\n",
    "                        sorted([(line[0], line[1]) for line in enumerate(row[1].bsheets.splitlines()) if\n",
    "                                snif.force_utf8(line[1], 'utf8') not in row[1].forced_utf8.splitlines()])\n",
    "                       for row in aguy.iterrows()]\n",
    "# aguy['eq_lines'] = [len([line[0] for line in enumerate(tuple(zip(row[1].bsheets.splitlines(),\n",
    "#                       row[1].forced_utf8.splitlines()))) if line[1][0] == line[1][1]])\n",
    "#                     == len\n",
    "#                     for row in aguy.iterrows()]\n",
    "\n",
    "aguy.last_item.iloc[6][1][0].decode('utf16').encode('utf8').decode('utf8')\n",
    "aguy.forced_utf8, aguy.bsheets\n",
    "aguy['missing_line'].iloc[5]\n",
    "# aguy.iloc[5].bsheets.splitlines(), aguy.iloc[5].forced_utf8.splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asheet = aguy.iloc[4].bsheets[0]\n",
    "utfsheet = aguy.iloc[4].forced_utf8[0]\n",
    "asheet == utfsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# asheet = aguy.sample(1).bsheets.values[0]\n",
    "# last_item(asheet)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-ffe2fcee5976>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m                   for row in aguy.iterrows()]\n\u001b[1;32m      4\u001b[0m \u001b[0mabyte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maguy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbsheets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bencod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabyte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mnonull\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrip_null\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabyte\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mnonull\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitllines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mabyte\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cimaq_memory/sniffbytes.py\u001b[0m in \u001b[0;36mget_bencod\u001b[0;34m(inpt)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_bencod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPathLike\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     \u001b[0minpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m     \u001b[0mdetector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mudet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m     \u001b[0mdetector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cimaq_memory/sniffbytes.py\u001b[0m in \u001b[0;36mget_bytes\u001b[0;34m(inpt)\u001b[0m\n\u001b[1;32m    122\u001b[0m                   0 and inpt != None) else b\"1\"][0]\n\u001b[1;32m    123\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuffering\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m             \u001b[0moutpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmyfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m             if bool(len(myfile.read().splitlines()) > \\\n",
      "\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "\n",
    "enc = snif.get_bencod(abyte)\n",
    "nonull = strip_null(abyte, enc)\n",
    "nonull.splitllines()[:4], abyte.splitlines()[:4]\n",
    "# aguy['no_null'] = [strip_null(row[1].bsheets,\n",
    "#                               row[1].encoding)#.encode(row[1].encoding)\n",
    "#                    for row in aguy.iterrows()]\n",
    "# aguy['bprints'] = [snif.bytes_printable(row[1].bsheets).encode(snif.get_bencod(row[1].bsheets))\n",
    "#                  for row in aguy.iterrows()]\n",
    "# checkfx = []\n",
    "\n",
    "\n",
    "# list(abyte.splitlines()[-1])\n",
    "# [chr(itm).encode() for itm in\n",
    "#  [list(row[1].bsheets.splitlines()[-1])[-1]\n",
    "# for row in aguy.iterrows()]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 1 fields in line 52, saw 2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-45f69c862d42>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         ''.join(snif.get_nullrep(inpt, encoding)), '').splitlines())\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkfrombytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;31m#     narep =''.encode(encoding).join([itm.encode(encoding) for itm in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#                                            snif.get_nullrep(inpt, encoding)])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1055\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1057\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   2059\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2060\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2063\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 1 fields in line 52, saw 2\n"
     ]
    }
   ],
   "source": [
    "inpt = list(test.values())[0].iloc[0].bsheets\n",
    "encoding = list(test.values())[0].iloc[0].encoding\n",
    "\n",
    "def strip_null(inpt: bytes, encoding: str = None) -> bytes:\n",
    "    ''' Remove null bytes from byte stream with proper representation\n",
    "        Adapted from:\n",
    "        https://stackoverflow.com/questions/21017698/converting-int-to-bytes-in-python-3\n",
    "        All files end by a null byte, so the last byte in a file shows\n",
    "        how null bytes are represented within this file '''\n",
    "    encoding = [encoding if encoding else snif.get_bencod(inpt)][0]\n",
    "    return '\\n'.join(inpt.decode(encoding, 'replace').replace('�', '').replace(\n",
    "        ''.join(snif.get_nullrep(inpt, encoding)), '').splitlines())\n",
    "\n",
    "pd.read_csv(StringIO(snif.mkfrombytes(inpt.strip()).decode()), sep = '\\t')\n",
    "#     narep =''.encode(encoding).join([itm.encode(encoding) for itm in\n",
    "#                                            snif.get_nullrep(inpt, encoding)])\n",
    "#     return inpt.replace(narep, '|'.encode(encoding))\n",
    "#         inpt = inpt.replace(narep.encode(encoding),\n",
    "#                             '|'.encode(encoding)).replace('|'.encode(encoding),\n",
    "#                                                           ''.encode(encoding))\n",
    "#         return inpt\n",
    "#     return snif.bytes_printable(inpt.replace(,\n",
    "#                                              repval).replace(chr(0).encode(encoding),\n",
    "#                                         repval).replace(chr(1).encode(encoding),\n",
    "#                                                         repval))\n",
    "# snif.mkfrombytes(strip_null(inpt, 'utf8').encode())\n",
    "# pd.read_csv(StringIO(snif.mkfrombytes(inpt).decode(encoding)),\n",
    "#             sep='\\t', header = [0 if snif.get_has_header(strip_null(inpt).encode(encoding)) else None][0])\n",
    "# inpt.decode(snif.get_bencod(strip_null(inpt)), 'ignore').replace('�', '')\n",
    "# pd.read_csv(StringIO(), sep='\\t')\n",
    "# [[list(itm for itm in line.split() if itm not in nareps)]\n",
    "#  for line in snif.bytes_printable(inpt)]\n",
    "# def get_na_reps(inpt: bytes, encoding: str = None) -> Union[list, int, bytes]:\n",
    "#     inpt = snif.bytes_printable(inpt)\n",
    "#     encoding = [encoding if encoding else snif.get_bencod(inpt)]\n",
    "#     return [chr(itm).encode(encoding) for itm\n",
    "#             in [chr(nulb) for nulb in\n",
    "#                 list(snif.get_nullrep(snif.bytes_printable(inpt)))][0]]\n",
    "\n",
    "# get_na_reps(inpt)\n",
    "# # [list(''.encode(encoding).join((line.split())))\n",
    "# #  for line in inpt.splitlines()]\n",
    "# chr(int.from_bytes('0xf8', sys.byteorder))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 3+5 ==9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-22-f7ebdff6db92>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-22-f7ebdff6db92>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    )\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from multiple_replace import multiple_replace\n",
    "\n",
    "def clear_nullbytes(inpt: bytes, encoding: str = None):\n",
    "    inpt = snif.bytes_printable(inpt)\n",
    "    encoding = snif.get_bencod(inpt)\n",
    "    toclear = dict((itm.encode(encoding), '|'.encode(encoding))\n",
    "                   for itm in\n",
    "                   )\n",
    "\n",
    "\n",
    "    for narep in nareps:\n",
    "        inpt = inpt.replace(narep, '|'.encode(encoding))\n",
    "    return inpt\n",
    "#     return inpt.replace('|'.encode(encoding), 'nan'.encode(encoding))\n",
    "# multiple_replace(toclear, snif.bytes_printable(abyte), encoding)\n",
    "# help(str.replace)\n",
    "# b_printable = ''.encode(encoding).join([ch.encode(encoding)\n",
    "#                               for ch in list(string.printable)])\n",
    "# b_printable\n",
    "\n",
    "inpt = list(test.values())[0].iloc[8].bsheets\n",
    "encoding = list(test.values())[0].iloc[8].encoding\n",
    "# new = snif.bytes_printable(abyte).replace(tostrip, ''.encode(encoding))\n",
    "clear_nullbytes(inpt, encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def bytes_prntble(inpt: bytes, encoding: str = None) -> bytes:\n",
    "#     ''' Same as is_printable, but for bytes in native file encoding '''\n",
    "#     encoding = [encoding if encoding else get_bencod(inpt)][0]\n",
    "\n",
    "#     b_printable = ''.encode(encoding).join([ch.encode(encoding)\n",
    "#                               for ch in list(string.printable)])\n",
    "#     return ''.encode(encoding).join([str(chr(int.from_bytes(ch, sys.byteorder))).encode(encoding) for ch in \n",
    "#                                     list(inpt) if str(chr(int.from_bytes(ch, sys.byteorder))).encode(encoding)\n",
    "#                                     in b_printable])\n",
    "    \n",
    "# def get_nullrep(inpt: bytes, encoding: str = None) -> bytes:\n",
    "#     ''' Returns null byte representation as bytes in native file encoding'''\n",
    "#     encoding = [encoding if encoding else get_bencod(inpt)][0]\n",
    "#     return bytes([inpt.splitlines(keepends = True)[-1][-1]]).decode(encoding).encode(encoding)\n",
    "\n",
    "# def strip_null(inpt: bytes, encoding: str = None, replace_val: str = None) -> bytes:\n",
    "#     ''' Remove null bytes from byte stream with proper representation\n",
    "#         Adapted from:\n",
    "#         https://stackoverflow.com/questions/21017698/converting-int-to-bytes-in-python-3\n",
    "#         All files end by a null byte, so the last byte in a file shows\n",
    "#         how null bytes are represented within this file '''\n",
    "#     encoding = [encoding if encoding else get_bencod(inpt)][0]\n",
    "#     repval = ['' if not replace_val else replace_val][0].encode(encoding)\n",
    "#     return bytes_prntble(inpt.replace(get_nullrep(inpt, encoding), repval).replace(chr(0).encode(encoding),\n",
    "#                                         repval).replace(chr(1).encode(encoding),\n",
    "#                                                         repval))\n",
    "\n",
    "# snif.get_nullrep(abyte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>862</th>\n",
       "      <th>863</th>\n",
       "      <th>864</th>\n",
       "      <th>865</th>\n",
       "      <th>866</th>\n",
       "      <th>867</th>\n",
       "      <th>868</th>\n",
       "      <th>869</th>\n",
       "      <th>870</th>\n",
       "      <th>871</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"'DI\\\\x11a!+-\\\\x1aa\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"'\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\\\x0b\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\\\x0c\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>'\"</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"'\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\\\x0e\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\\\x0f\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\\\x10\\</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"'e\\</td>\n",
       "      <td>n\\</td>\n",
       "      <td>c\\</td>\n",
       "      <td>o\\</td>\n",
       "      <td>d\\</td>\n",
       "      <td>i\\</td>\n",
       "      <td>n\\</td>\n",
       "      <td>g\\</td>\n",
       "      <td>-\\</td>\n",
       "      <td>s\\</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"'\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\</td>\n",
       "      <td>\\\\x16\\</td>\n",
       "      <td>yy\\\\x01\\</td>\n",
       "      <td>'\"</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>\"'s\\</td>\n",
       "      <td>t\\</td>\n",
       "      <td>i\\</td>\n",
       "      <td>m\\</td>\n",
       "      <td>.\\</td>\n",
       "      <td>c\\</td>\n",
       "      <td>r\\</td>\n",
       "      <td>e\\</td>\n",
       "      <td>s\\</td>\n",
       "      <td>p\\</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>\"'c\\</td>\n",
       "      <td>o\\</td>\n",
       "      <td>r\\</td>\n",
       "      <td>r\\</td>\n",
       "      <td>e\\</td>\n",
       "      <td>c\\</td>\n",
       "      <td>t\\</td>\n",
       "      <td>s\\</td>\n",
       "      <td>o\\</td>\n",
       "      <td>u\\</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>\"'e\\</td>\n",
       "      <td>v\\</td>\n",
       "      <td>e\\</td>\n",
       "      <td>n\\</td>\n",
       "      <td>t\\</td>\n",
       "      <td>l\\</td>\n",
       "      <td>i\\</td>\n",
       "      <td>s\\</td>\n",
       "      <td>t\\</td>\n",
       "      <td>b\\</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>\"'s\\</td>\n",
       "      <td>t\\</td>\n",
       "      <td>i\\</td>\n",
       "      <td>m\\</td>\n",
       "      <td>.\\</td>\n",
       "      <td>d\\</td>\n",
       "      <td>u\\</td>\n",
       "      <td>r\\</td>\n",
       "      <td>a\\</td>\n",
       "      <td>t\\</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>\"'s\\</td>\n",
       "      <td>t\\</td>\n",
       "      <td>i\\</td>\n",
       "      <td>m\\</td>\n",
       "      <td>.\\</td>\n",
       "      <td>c\\</td>\n",
       "      <td>r\\</td>\n",
       "      <td>e\\</td>\n",
       "      <td>s\\</td>\n",
       "      <td>p\\</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>386 rows × 872 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0   1   2       3         4   5       6     7     8    \\\n",
       "0    \"'DI\\\\x11a!+-\\\\x1aa\\   \\   \\       \\         \\   \\       \\     \\     \\   \n",
       "1                     \"'\\   \\   \\  \\\\x0b\\         \\   \\  \\\\x0c\\     \\     \\   \n",
       "2                     \"'\\   \\   \\  \\\\x0e\\         \\   \\  \\\\x0f\\     \\     \\   \n",
       "3                    \"'e\\  n\\  c\\      o\\        d\\  i\\      n\\    g\\    -\\   \n",
       "4                     \"'\\   \\   \\  \\\\x16\\  yy\\\\x01\\  '\"    None  None  None   \n",
       "..                    ...  ..  ..     ...       ...  ..     ...   ...   ...   \n",
       "381                  \"'s\\  t\\  i\\      m\\        .\\  c\\      r\\    e\\    s\\   \n",
       "382                  \"'c\\  o\\  r\\      r\\        e\\  c\\      t\\    s\\    o\\   \n",
       "383                  \"'e\\  v\\  e\\      n\\        t\\  l\\      i\\    s\\    t\\   \n",
       "384                  \"'s\\  t\\  i\\      m\\        .\\  d\\      u\\    r\\    a\\   \n",
       "385                  \"'s\\  t\\  i\\      m\\        .\\  c\\      r\\    e\\    s\\   \n",
       "\n",
       "        9    ...   862   863   864   865   866   867   868   869   870   871  \n",
       "0         \\  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "1        '\"  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "2    \\\\x10\\  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "3        s\\  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "4      None  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "..      ...  ...   ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
       "381      p\\  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "382      u\\  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "383      b\\  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "384      t\\  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "385      p\\  ...  None  None  None  None  None  None  None  None  None  None  \n",
       "\n",
       "[386 rows x 872 columns]"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abyte = list(test.values())[0].iloc[1].bsheets\n",
    "enc = snif.get_bencod(abyte)\n",
    "# (abyte.decode(enc, 'replace').splitlines()[0], repr(abyte.decode(enc, 'replace').splitlines()[0]),\n",
    "#  repr(snif.force_utf8(abyte).splitlines()[0].decode())\n",
    "# )\n",
    "repr(abyte.decode(enc, 'replace'))\n",
    "def to_utf8(astring):\n",
    "    return unidecode(repr(astring.decode(enc, 'replace').replace('�', '').encode(\n",
    "              'ISO-8859-1', 'ignore').decode('ISO-8859-1', 'replace').replace('�', ''))).encode()\n",
    "# len(to_utf8(abyte).splitlines()\n",
    "# )\n",
    "len(abyte.splitlines())\n",
    "new = b'\\n'.join([b'\\t'.join([to_utf8(itm) for itm in to_utf8(line).split()])\n",
    "            for line in abyte.splitlines()]).decode()\n",
    "\n",
    "df([' '.join(line.split(\"\\\\x00\")).split() for line in new.splitlines()])\n",
    "# clean_utf8 = '\\n'.join([['\\t'.join([to_utf8(itm) for itm in line.split()])]\n",
    "#               for line in abyte.splitlines()])\n",
    "# clean_utf8\n",
    "# newsheet = repr(abyte.replace(bytes(str(chr(0)), enc),\n",
    "#               str(np.nan).encode(enc)).replace(\n",
    "#                   bytes(\"'\\\\\\\\x0'\", enc), str(np.nan).encode(enc)).replace(\n",
    "#                   bytes(\"'\\\\\\\\x'\", enc), ''.encode(enc)).replace(\n",
    "#                       bytes(str(np.nan), enc), str(\"\").encode(enc)).decode(\n",
    "#                           'ascii', 'replace').replace('�', '').replace('ÿ', ''))\n",
    "\n",
    "# cleaned = '\\n'.join(['\\t'.join([itm.replace('\\\\x0', ' ').strip().replace('\\\\x', ' ').strip() for itm in line.split()])\n",
    "#            for line in repr(newsheet).replace('\\\\x00', ' ').splitlines()]).strip()[1:].encode().decode()\n",
    "# pd.read_csv(StringIO(unidecode(cleaned)), sep='\\t')\n",
    "# [line.replace('\\\\x00', str(np.nan)).replace('\\\\x0', str(np.nan)) for line in newsheet.splitlines() if line != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-16-le' codec can't decode byte 0x00 in position 0: truncated data",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-95431c22d013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0menc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msnif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_bencod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip_null\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabyte\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# snif.strip_null(abyte)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# [strip_null(line) for line in strip_null(bytes_prntble(abyte)).splitlines(keepends = True)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cimaq_memory/sniffbytes.py\u001b[0m in \u001b[0;36mstrip_null\u001b[0;34m(inpt, encoding, replace_val)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mget_bencod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0mrepval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mreplace_val\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mreplace_val\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m     return bytes_prntble(inpt.replace(get_nullrep(inpt, encoding), repval).replace(chr(0).encode(encoding),\n\u001b[0m\u001b[1;32m    183\u001b[0m                                         \u001b[0mrepval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                                                         repval))\n",
      "\u001b[0;32m~/cimaq_memory/sniffbytes.py\u001b[0m in \u001b[0;36mget_nullrep\u001b[0;34m(inpt, encoding)\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;34m''' Returns null byte representation as bytes in native file encoding'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mget_bencod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeepends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstrip_null\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace_val\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-16-le' codec can't decode byte 0x00 in position 0: truncated data"
     ]
    }
   ],
   "source": [
    "# abyte = list(test.values())[0].iloc[2].bsheets\n",
    "# encod = list(test.values())[0].iloc[2].encoding\n",
    "\n",
    "\n",
    "    \n",
    "enc = snif.get_bencod(snif.strip_null(abyte))\n",
    "# snif.strip_null(abyte)\n",
    "# [strip_null(line) for line in strip_null(bytes_prntble(abyte)).splitlines(keepends = True)]\n",
    "\n",
    "# get_nullrep(abyte)+b'1'\n",
    "# # int.from_bytes(b'\\\\x0', 'little'), int.from_bytes(b'\\\\x0', sys.byteorder), int.from_bytes(b'\\\\x0', 'big')\n",
    "\n",
    "# # newsheet = '\\n'.join(['\\t'.join([str(itm).replace(\"'\", \"\").replace(\"'\", '\"') for itm in\n",
    "# #                                  repr(line).replace('ÿ', '\\s').replace('\\\\x0', '\\s').replace(\n",
    "# #                                      '\\\\x', '\\s').replace('\\s', '').split()])\n",
    "# #                       for line in list(test.values())[0].iloc[5].bsheets.decode(\n",
    "# #                encod, 'replace').splitlines()]).splitlines()\n",
    "# # newsheet\n",
    "# # strtest = abyte.splitlines()[0]\n",
    "\n",
    "# repr(abyte.replace(repr(chr(0)).encode(encod), ''.encode(encod)).decode(encod, 'replace').replace('�', '')).encode(\n",
    "#     'ISO-8859-1', 'ignore').decode('ISO-8859-1', 'replace').replace('�', '').encode()\n",
    "# abyte.decode('ISO-8859-1').encode('ascii', 'ignore').decode('utf8', 'replace').replace('�', '')\n",
    "\n",
    "# unidecode(repr(abyte.decode(encod, 'replace').replace('�', '')))\n",
    "# is_printable(abyte.decode(encod, 'replace').replace('�', '').encode().replace(chr(0).encode(), ''.encode()).decode())\n",
    "\n",
    "# # new = [[unidecode(itm).encode('ascii', 'ignore').decode('ascii', 'replace').replace('�', '')\n",
    "# #         for itm in line.replace(repr(chr(0)),\n",
    "# #                                '').split()\n",
    "# #       if unidecode(is_printable(itm)) != '']\n",
    "# #      for line in abyte.decode(encod, 'replace').replace('�', '').splitlines()\n",
    "# #      if line != []]\n",
    "# # new[0], ''.join(new[0]).replace(repr(chr(0)).encode(encod), ' '.encode(encod))\n",
    "# new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'z'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'a' in string.printable #list(string.printable)\n",
    "\n",
    "chr(int.from_bytes(b'z', sys.byteorder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "an integer is required (got type str)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dabd634a8b15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# chr(int.from_bytes(b'\\\\x00', 'big'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# chr(int.from_bytes('\\\\x0'.encode('Windows-1252'), sys.byteorder))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# chr(int.from_bytes(b'\\\\x00', sys.byteorder))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-dabd634a8b15>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# chr(int.from_bytes(b'\\\\x00', 'big'))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mchr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprintable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# chr(int.from_bytes('\\\\x0'.encode('Windows-1252'), sys.byteorder))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# chr(int.from_bytes(b'\\\\x00', sys.byteorder))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: an integer is required (got type str)"
     ]
    }
   ],
   "source": [
    "# chr(int.from_bytes(b'\\\\x00', 'big'))\n",
    "[chr(itm).encode() for itm in list(string.printable)]\n",
    "# chr(int.from_bytes('\\\\x0'.encode('Windows-1252'), sys.byteorder))\n",
    "# chr(int.from_bytes(b'\\\\x00', sys.byteorder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x11\\u0871\\x1a>\\x03'"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# abyte.decode('utf8', 'replace').replace('�', '').encode().decode()\n",
    "# unidecode(abyte.decode(snif.get_bencod(abyte), 'replace').replace('�', '')).encode()\n",
    "snif.force_utf8(abyte, enc).splitlines()\n",
    "clean1 = re.sub('\\\\x00', '', abyte.decode('ascii', 'replace').replace('�', '').encode('utf16').decode('utf8', 'replace'))\n",
    "# unidecode(clean1.encode().decode()).encode('utf16', 'replace')\n",
    "clean1\n",
    "[re.sub(bytes(str(np.nan), enc), bytes('', enc),\n",
    "        re.sub(bytes(\"\\x00\", enc),\n",
    "               bytes(str(np.nan), enc),\n",
    "               line)).decode('utf8', 'replace').replace('�', '').replace('\\\\', '')#unidecode(line.decode(enc, 'replace'))).encode('ascii', 'replace').decode('utf8', 'replace').replace('�', '')\n",
    "  for line in abyte.splitlines()][0].split()[0]\n",
    "# snif.force_utf8(abyte.decode(enc, 'replace'))\n",
    "#.decode(enc, 'replace')]\n",
    "# re.sub('\\x0', '', clean1)\n",
    "# unidecode(\n",
    "#           .replace('\\x00', '').replace(\n",
    "#     '\\\\x0', '').replace('\\\\x', ''))\n",
    "#.replace(b\"\\x\".decode(), '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\x01'"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# chr(0)\n",
    "# str(\"\\xff\")\n",
    "chr(1).encode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes('n\\a', 'Windows-1252')\n",
    "unidecode(b'\\x0b\\x0c'.decode(enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_tsvs(cimaq_dir):\n",
    "#     qc_ok = sorted([str(itm[0]) for itm in\n",
    "#                 pd.read_csv(get_cimaq_dir_paths(\n",
    "#                     cimaq_dir)[0].mean_qc.fpaths, sep='\\t').values])\n",
    "#     qc_ok\n",
    "#     to_exclude = df(sorted([(str(bname(itm).split('_')[0]),\n",
    "#                          str(bname(itm).split('_')[1]), itm) for itm in\n",
    "#                         loadimages(get_cimaq_dir_paths(\n",
    "#                             cimaq_dir)[0].zeprimes.fpaths)\n",
    "#                         if str(bname(itm).split('_')[1]) not in qc_ok]),\n",
    "#                    columns = ['pscid', 'dccid', 'fpaths'])`.set_index(\n",
    "#                        'dccid').sort_index().reset_index().fpaths.tolist()\n",
    "\n",
    "#     repair_dataset(get_cimaq_dir_paths(cimaq_dir)[0].zeprimes.fpaths,\n",
    "#                    get_cimaq_dir_paths(cimaq_dir)[0].temp_events_dir.fpaths,\n",
    "#                    exclude = ['pratique', 'practice', '.pdf', '.edat2'] + to_exclude)\n",
    "#     allids = repair_enc_task(cimaq_dir)\n",
    "#     pscids, dccids, subids = allids.pscid, allids.dccid, allids.subids\n",
    "#     cimaq = pd.concat([subids, pscids, dccids] + \\\n",
    "#                        [loadfiles(loadimages(row[1].fpaths)).dropna(axis = 0).T\n",
    "#                         for row in get_cimaq_dir_paths(cimaq_dir)[0].T.iloc[2: 4].iterrows()]).T\n",
    "#     test = dict((grp, dict((sgrp, cimaq.groupby('subids').get_group(grp).groupby(\n",
    "#                'fname').get_group(sgrp)) for sgrp in allscans.groupby(\n",
    "#                    'subids').get_group(grp).groupby('fname').groups))\n",
    "#                 for grp in allscans.groupby('subids').groups)\n",
    "# #     cimaq = pd.concat([subids, pscids, dccids] + \\\n",
    "# #                       [loadfiles(loadimages(cimaqrow[1].fpaths)).dropna(axis = 0).rename(\n",
    "# #                 columns = {'fpaths': cimaqrow[1].suffixes})#['fpaths']\n",
    "# #                                   for cimaqrow in get_cimaq_dir_paths(cimaq_dir)[0].T.iloc[1: 6].iterrows()],\n",
    "# #                       axis = 1).dropna(axis = 0).T.reset_index(drop = True).T\n",
    "# #     cimaq = cimaq.rename(columns = {0: 'subid', 1: 'pscid', 2: 'dccid', 3: 'stereonl', 4: 'behavioral',\n",
    "# #                                     5: 'confounds', 6: 'events', 7:'func'})\n",
    "#     return test\n",
    "# cimaq = load_tsvs(cimaq_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/francois/../../media/francois/seagate_1tb/cimaq_03-19/cimaq_03-19/derivatives/CIMAQ_fmri_memory/data/task_files/zipped_eprime/participants/sub_list_TaskQC.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-12a57bd711e1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcimaq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfetch_cimaq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcimaq_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#cimaq.sort_values('dccid').set_index('dccid', drop = True).reset_index()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cimaq_memory/cimaq_utils.py\u001b[0m in \u001b[0;36mfetch_cimaq\u001b[0;34m(cimaq_dir)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mdst_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdlst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtemp_events_dir\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuffixes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m     qc_ok = sorted([str(itm[0]) for itm in\n\u001b[0;32m--> 106\u001b[0;31m                 pd.read_csv(get_cimaq_dir_paths(\n\u001b[0m\u001b[1;32m    107\u001b[0m                     cimaq_dir)[0].mean_qc.fpaths, sep='\\t').values])\n\u001b[1;32m    108\u001b[0m     \u001b[0mqc_ok\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    608\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 610\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    611\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    460\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    817\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1048\u001b[0m             )\n\u001b[1;32m   1049\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1050\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1051\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1052\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1865\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1866\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1867\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1868\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1869\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1360\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m         \"\"\"\n\u001b[0;32m-> 1362\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1363\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"replace\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 642\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/francois/../../media/francois/seagate_1tb/cimaq_03-19/cimaq_03-19/derivatives/CIMAQ_fmri_memory/data/task_files/zipped_eprime/participants/sub_list_TaskQC.tsv'"
     ]
    }
   ],
   "source": [
    "cimaq = fetch_cimaq(xpu(cimaq_dir))\n",
    "#cimaq.sort_values('dccid').set_index('dccid', drop = True).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cimaq' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-191-cf3e65e25457>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcimaq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'cimaq' is not defined"
     ]
    }
   ],
   "source": [
    "cimaq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetch_cimaq(cimaq_dir):\n",
    "#     qc_ok = sorted([str(itm[0]) for itm in\n",
    "#                 pd.read_csv(get_cimaq_dir_paths(\n",
    "#                     cimaq_dir)[0].mean_qc.fpaths, sep='\\t').values])\n",
    "#     qc_ok\n",
    "#     to_exclude = df(sorted([(str(bname(itm).split('_')[0]),\n",
    "#                          str(bname(itm).split('_')[1]), itm) for itm in\n",
    "#                         loadimages(get_cimaq_dir_paths(\n",
    "#                             cimaq_dir)[0].zeprimes.fpaths)\n",
    "#                         if str(bname(itm).split('_')[1]) not in qc_ok]),\n",
    "#                    columns = ['pscid', 'dccid', 'fpaths']).set_index(\n",
    "#                        'dccid').sort_index().reset_index().fpaths.tolist()\n",
    "\n",
    "#     repair_dataset(get_cimaq_dir_paths(cimaq_dir)[0].zeprimes.fpaths,\n",
    "#                    get_cimaq_dir_paths(cimaq_dir)[0].temp_events_dir.fpaths,\n",
    "#                    exclude = ['pratique', 'practice', '.pdf', '.edat2'] + to_exclude)\n",
    "#     allids = repair_enc_task(cimaq_dir)\n",
    "#     pscids, dccids, subids = allids.pscid, allids.dccid, allids.subids\n",
    "#     cimaq = pd.concat([subids, pscids, dccids] + [loadfiles(loadimages(cimaqpath)).dropna(axis = 0)['fpaths']\n",
    "#                                   for cimaqpath in get_cimaq_dir_paths(cimaq_dir)[0].loc['fpaths'][2: 5]],\n",
    "#                       axis = 1).dropna(axis = 0).T.reset_index(drop = True).T\n",
    "#     cimaq = cimaq.rename(columns = {0: 'subid', 1: 'pscid', 2: 'dccid', 3: 'behavioral', 4: 'confounds',\n",
    "#                                     5: 'events'})\n",
    "#     return cimaq.set_index('dccid').sort_index()#.reset_index(drop = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_scans(cimaq_dir):\n",
    "    cimaq = fetch_cimaq(cimaq_dir)\n",
    "\n",
    "#     cimaq = pd.concat([subids, pscids, dccids] + \\\n",
    "#                   [loadfiles(loadimages(cimaqrow[1].fpaths)).dropna(axis = 0).rename(\n",
    "#             columns = {'fpaths': cimaqrow[1].suffixes})#['fpaths']\n",
    "#                               for cimaqrow in get_cimaq_dir_paths(cimaq_dir)[0].T.iloc[1: 6].iterrows()],\n",
    "#                   axis = 1).dropna(axis = 0).T.reset_index(drop = True).T\n",
    "    \n",
    "    allscans = pd.concat([loadfiles(loadimages(pjoin(dname(xpu(cimaq_dir)),\n",
    "                                                     sub))).dropna(axis = 0).T\n",
    "                          for sub in [itm for itm in ls(dname(xpu(cimaq_dir)))\n",
    "                        if itm.startswith('sub-')]], axis = 1).T\n",
    "    allscans[['dccid', 'modality', 'general']] = [(bname(row[1].fpaths).split('_')[0].split('-')[1],\n",
    "                                                   bname(row[1].fpaths).split('_')[-1],\n",
    "                                                   bname(dname(row[1].fpaths)))\n",
    "                         for row in allscans.iterrows()]\n",
    "\n",
    "    test = dict((grp, dict((sgrp, allscans.groupby('dccid').get_group(grp).groupby(\n",
    "               'general').get_group(sgrp)) for sgrp in allscans.groupby(\n",
    "                   'dccid').get_group(grp).groupby('general').groups))\n",
    "                for grp in allscans.groupby('dccid').groups)\n",
    "    allscans = df.from_dict(test, orient = 'index').sort_index()\n",
    "    indexes = set.intersection(set(cimaq.index), set(allscans.index)) \n",
    "    return pd.concat([allscans.loc[indexes], cimaq.loc[indexes]], axis = 0)\n",
    "test = load_scans(cimaq_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2.iloc[0].fmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params = [pd.concat([row[1][['fname']], df.from_dict(json_read(row[1].fpaths, 'r'), orient = 'index')])\n",
    "#           for row in test[0].iterrows()\n",
    "#           if row[1].ext == '.json']\n",
    "# # allparams = pd.concat(((itm.groupby('fname').get_group(grp)\n",
    "# #                  for grp in itm.groupby('fname').groups)\n",
    "# #              for itm in allparams), axis = 1)\n",
    "# # pd.concat(params, axis =1).T.sort_values('fname')\n",
    "# pd.concat(params, axis = 1).T.set_index('fname')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _update_timestamp(path: os.PathLike, set_new: bool) -> None:\n",
    "    \"\"\"\n",
    "    Context manager to set the timestamp of the path to plus or\n",
    "    minus a fixed delta, regardless of modifications within the context.\n",
    "\n",
    "    if set_new is True, the delta is added. Otherwise, the delta is subtracted.\n",
    "    \"\"\"\n",
    "    stats = os.stat(path)\n",
    "    if set_new:\n",
    "        new_timestamp = (stats.st_atime_ns + _TIMESTAMP_DELTA, stats.st_mtime_ns + _TIMESTAMP_DELTA)\n",
    "    else:\n",
    "        new_timestamp = (stats.st_atime_ns - _TIMESTAMP_DELTA, stats.st_mtime_ns - _TIMESTAMP_DELTA)\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        os.utime(path, ns=new_timestamp)\n",
    "\n",
    "\n",
    "# Public Methods "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
