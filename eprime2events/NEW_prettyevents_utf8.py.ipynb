{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['sheetpaths'], dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d47f17e15161>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-4-d47f17e15161>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0myallofems\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencsheets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretsheets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNEW_prettyevents_utf8\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-d47f17e15161>\u001b[0m in \u001b[0;36mNEW_prettyevents_utf8\u001b[0;34m(maindir, outdir)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# Clear previous attempts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     p1 = pd.read_csv(join(maindir, \"participants.tsv\"),\n\u001b[0;32m---> 31\u001b[0;31m                      sep='\\t').set_index(\"sub-ID\")[[\"sheetpaths\"]]\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;34m[\u001b[0m\u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mp1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2910\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2911\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2912\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2914\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1252\u001b[0m             \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_indexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reindex_non_unique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1254\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_read_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraise_missing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraise_missing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1255\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                 \u001b[0maxis_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1298\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of [{key}] are in the [{axis_name}]\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1300\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['sheetpaths'], dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: UTF-8 -*-\n",
    "\n",
    "import csv\n",
    "import ctypes\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shutil\n",
    "import time\n",
    "import zipfile\n",
    "from os import listdir as ls\n",
    "from os.path import basename as bname\n",
    "from os.path import dirname as dname\n",
    "from os.path import expanduser as xpu\n",
    "from os.path import join\n",
    "from pandas import DataFrame as df\n",
    "from cimaq_utils import flatten\n",
    "from cimaq_utils import loadimages\n",
    "\n",
    "def NEW_prettyevents_utf8(maindir=\"~/extracted_eprime0_utf8\",\n",
    "                    outdir=\"~/cimaq_newsheets_utf8\"):\n",
    "# TrialNum ImageID Trial_part  onsetSec  durationSec\n",
    "    maindir = xpu(maindir)\n",
    "    \n",
    "# Clear previous attempts\n",
    "    p1 = pd.read_csv(join(maindir, \"participants.tsv\"),\n",
    "                     sep='\\t').set_index(\"sub-ID\")[[\"sheetpaths\"]]\n",
    "    [shutil.rmtree(join(outdir, row[0])) for row in p1.iterrows()]\n",
    "\n",
    "# Headers for each of the 3 '.txt' files (open-source '.edat2' (E-prime) equivalent)\n",
    "    prefixes = [\"Onset-Event-Encoding_CIMAQ_\", \"Output-Responses-Encoding_CIMAQ_\",\n",
    "                \"Output_Retrieval_CIMAQ_\"]\n",
    "    EncOnsetCols = [\"TrialNum\", \"Condition\", \"TrialNum_perCondi\",\n",
    "                  \"ImageID\", \"Trial_part\", \"onsetSec\", \"durationSec\"]\n",
    "\n",
    "    allsheets = NEW_get_allsheetsdf()\n",
    "\n",
    "    # Initiate empty list for each outputed variable for backup\n",
    "    full_on_eve_enc, retsheets, fixnstimtimes, timings = [], [], [], []\n",
    "    fixsheets, encsheets, s_ids, yallofems = [], [], [], []\n",
    "    \n",
    "    # Create output directories structure\n",
    "    allsheets[\"enc_outpaths\"] = [join(outdir, row[0], \"events\") for row in allsheetsdf.iterrows()]\n",
    "    allsheets[\"ret_outpaths\"] = [join(outdir, row[0], \"behavioral\") for row in allsheetsdf.iterrows()]\n",
    "    [(os.makedirs(join(outdir, row[0], \"events\"), exist_ok=True),\n",
    "     os.makedirs(join(outdir, row[0], \"behavioral\"), exist_ok=True))\n",
    "     for row in allsheetsdf.iterrows()]\n",
    "    def sheetspersub(allsheets, prefixes):\n",
    "        return dict((pre[1], [[(row[0], row[1]['sheetpath'])\n",
    "                                for row in allsheets.iterrows()\n",
    "                                if row[1]['prefix'] == prefixes[pre[0]]]\n",
    "                               for row in p1.iterrows()])\n",
    "                     for pre in enumerate(prefixes))\n",
    "    encsheetsA = [(row[0], row[1]['sheetpath'])\n",
    "                  for row in allsheets.iterrows()\n",
    "                  if row[1]['prefix'] == prefixes[0]]\n",
    "        \n",
    "    encsheetsB = [row[1]['sheetpath'] for row in allsheets.iterrows() if row[1]['prefix'] == prefixes[1]]\n",
    "        \n",
    "    retsheets = [row[1]['sheetpath'] for row in allsheets.iterrows()if row[1]['prefix'] == prefixes[2]]\n",
    "\n",
    "    # Rows are individual sheets, 3 per participant\n",
    "    for row in allsheetsdf.iterrows():\n",
    "        if row[1]['prefix'] == prefixes[0]:\n",
    "\n",
    "            newsheet = pd.read_fwf(row[1]['sheetpath'], encoding=row[1]['encoding'],\n",
    "                header=None, sep='\\t', names=EncOnsetCols).iloc[6:]\n",
    "\n",
    "            # Identify stimulus & fixation cross as 2 possible conditions of a same trial\n",
    "            # instead of separate (double) trials\n",
    "            stimids = newsheet[[\"ImageID\",\n",
    "                               \"TrialNum_perCondi\"]].drop_duplicates(\\\n",
    "                               subset=[\"ImageID\", \"TrialNum_perCondi\"]).reset_index(drop=True)\n",
    "            s_ids.append((row[0]+\"_\"+row[1]['prefix']+\"_stimids\", stimids))\n",
    "            newsheet.to_excel(join(maindir, \"temp_\"+row[0]+\"_\"+row[1]['prefix']+'.xlsx'))\n",
    "            newsheet = pd.read_excel(join(\\\n",
    "                           maindir, \"temp_\"+row[0]+\"_\"+row[1]['prefix']+'.xlsx')).drop(\\\n",
    "                               ['TrialNum_perCondi', 'Condition'], axis=1)\n",
    "\n",
    "            tempsheet = newsheet[['TrialNum', 'Trial_part', 'onsetSec', 'durationSec']]\n",
    "\n",
    "            # Extract and concatenate relevant info\n",
    "            fixsheet = df([row[1] for row in tempsheet.iterrows()\n",
    "                                  if row[1]['Trial_part'] == 'Fixation'])\n",
    "            timing = tempsheet.loc[[row[0] for row in tempsheet.iterrows()\n",
    "                                     if row[0] not in fixsheet.index]]\n",
    "            fixsheet = fixsheet.rename(columns={\"onsetSec\": \"fixOnsetSec\",\n",
    "                                               \"durationSec\": \"fixDurSec\"})\n",
    "            fixsheet = fixsheet.transpose().iloc[-2:].transpose(\\\n",
    "                           ).reset_index(drop=True)\n",
    "#             fixsheets.append(((row[0]+\"_\"+row[1]['prefix']+\"_fixsheet_\", fixsheet)))\n",
    "\n",
    "            timing = timing.rename(columns={\"onsetSec\": \"stimOnsetSec\",\n",
    "                                            \"durationSec\": \"stimDurSec\"})\n",
    "            timing = timing.transpose().iloc[-2:].transpose().reset_index(drop=True)\n",
    "#             timings.append((row[0]+\"_\"+row[1]['prefix']+\"_timing_\", timing))\n",
    "            fixnstimtime = pd.concat([timing, fixsheet], axis=1, sort=False)\n",
    "#             fixnstimtimes.append((row[0]+\"_\"+row[1]['prefix']+\"_fixnstimtime_\", fixnstimtime))\n",
    "            allofem = pd.concat([fixnstimtime, stimids], axis=1, sort=False)\n",
    "            yallnametuple = (row[0]+\"_\"+row[1]['prefix'], allofem)\n",
    "            yallofems.append(yallnametuple)\n",
    "            row[1]['oldname'] = yallnametuple[0]\n",
    "\n",
    "        if row[1]['prefix'] == prefixes[1]:\n",
    "            encsheet = pd.read_csv(row[1]['sheetpath'],\n",
    "                                   encoding=row[1]['encoding'],\n",
    "                                   header=0,\n",
    "                                   sep='\\t').iloc[3:].fillna(False).rename(\\\n",
    "                           columns={\"TrialNumber\": \"TrialNum\",\n",
    "                                    \"Category\": \"Condition\"}).set_index(\"TrialNum\")\n",
    "            encsheet = encsheet.drop([\"TrialCode\"], axis=1)\n",
    "            encsheet[\"Condition\"] = encsheet[\"Condition\"].astype(\\\n",
    "                                        'str').replace({'CTL': '0', 'Enc': '1'})\n",
    "            encnametuple = (row[0]+\"_\"+row[1]['prefix'],\n",
    "                              encsheet.reset_index(drop=True))\n",
    "            encsheets.append(encnametuple)\n",
    "            row[1]['oldname'] = encnametuple[0]\n",
    "\n",
    "        # Immediately removing last row since it was an Eprime error (St-Laurent, 2019)\n",
    "        if row[1]['prefix'] == prefixes[2]:\n",
    "            retsheet = pd.read_csv(row[1]['sheetpath'],\n",
    "                                   encoding=row[1]['encoding'],\n",
    "                                   header=0, sep='\\t').iloc[:, :-1]\n",
    "            retnametuple = (row[1]['prefix']+\"_\"+row[0],\n",
    "                              retsheet.reset_index(drop=True))\n",
    "            retsheets.append(retnametuple)\n",
    "            row[1]['oldname'] = retnametuple[0]\n",
    "        encoding = tuple(zip(sorted(yallofems), sorted(encsheets)))\n",
    "        fullencsheets = [(item[0][0], pd.concat([item[0][1], item[1][1]], axis=1))\n",
    "                        for item in encoding]\n",
    "            \n",
    "    return sorted(yallofems), sorted(encsheets), sorted(retsheets)\n",
    "\n",
    "def main():\n",
    "    yallofems, encsheets, retsheets = NEW_prettyevents_utf8()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yallofems, encsheets, retsheets = NEW_prettyevents_utf8()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
